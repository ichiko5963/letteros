# RAG Implementation Guide - Retrieval-Augmented Generation

## ğŸ“š ç›®æ¬¡

1. RAGã®åŸºç¤æ¦‚å¿µã¨LetterOSã§ã®æ´»ç”¨
2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
4. Embeddingsç”Ÿæˆ
5. æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…
6. LangChainçµ±åˆ
7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
8. å®Ÿè£…ä¾‹é›†

## 1. RAGã®åŸºç¤æ¦‚å¿µã¨LetterOSã§ã®æ´»ç”¨

RAG (Retrieval-Augmented Generation)ã¯ã€å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ã¦LLMã®å¿œç­”ã‚’å¼·åŒ–ã™ã‚‹æŠ€è¡“ã§ã™ã€‚LetterOSã§ã¯ã€éå»ã®ãƒ¡ãƒ«ãƒã‚¬ã€æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãƒ–ãƒ©ãƒ³ãƒ‰ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æ¤œç´¢ã—ã€AIç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚

### LetterOSã§ã®RAGãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

1. **éå»ã®ãƒ¡ãƒ«ãƒã‚¬åˆ†æ**: æˆåŠŸã—ãŸãƒ¡ãƒ«ãƒã‚¬ã®ç‰¹å¾´ã‚’å­¦ç¿’
2. **ãƒ–ãƒ©ãƒ³ãƒ‰ãƒœã‚¤ã‚¹ç¶­æŒ**: ä¼æ¥­ã®æ–‡ä½“ãƒ»ãƒˆãƒ¼ãƒ³ã‚’ä¸€è²«
3. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¥­ç•Œãƒ»èª­è€…å±¤ã«åˆã‚ã›ãŸææ¡ˆ
4. **è¨¼æ‹ ï¼ˆProofï¼‰æ¤œç´¢**: ä¸»å¼µã‚’è£ä»˜ã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„äº‹ä¾‹ã‚’è‡ªå‹•æ¤œç´¢

### RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¦‚è¦

```mermaid
graph LR
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª] --> B[ã‚¯ã‚¨ãƒªã®EmbeddingåŒ–]
    B --> C[ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢]
    C --> D[é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—]
    D --> E[ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰]
    E --> F[LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ]
    F --> G[AIå¿œç­”ç”Ÿæˆ]
```

## 2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LetterOS RAG System                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  User Query  â”‚â”€â”€â”€â”€â”€>â”‚  LangChain   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  Pipeline    â”‚              â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                               â”‚                       â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚           â”‚                   â”‚                   â”‚   â”‚
â”‚      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚      â”‚ Embeddingâ”‚      â”‚  Vector   â”‚      â”‚    LLM    â”‚
â”‚      â”‚  Model   â”‚      â”‚  Database â”‚      â”‚  (OpenAI) â”‚
â”‚      â”‚ (OpenAI) â”‚      â”‚(Supabase) â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚         Document Processing               â”‚        â”‚
â”‚  â”‚  â€¢ Chunking  â€¢ Metadata  â€¢ Indexing      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | æŠ€è¡“ | ç”¨é€” |
|--------------|------|------|
| Vector DB | Supabase (pgvector) | ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜ãƒ»æ¤œç´¢ |
| Embeddings | OpenAI text-embedding-3-small | ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ– |
| LLM | OpenAI GPT-4 | ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ |
| Orchestration | LangChain | RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç† |
| Caching | Redis (Upstash) | æ¤œç´¢çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ |

## 3. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### Supabase pgvectoræ‹¡å¼µ

```sql
-- pgvectoræ‹¡å¼µã‚’æœ‰åŠ¹åŒ–
CREATE EXTENSION IF NOT EXISTS vector;

-- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    metadata JSONB,
    embedding VECTOR(1536), -- text-embedding-3-smallã¯1536æ¬¡å…ƒ
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆIVFFlatï¼‰
CREATE INDEX ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX ON documents USING GIN (metadata);
CREATE INDEX ON documents (user_id);

-- é–¢æ•°: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢
CREATE OR REPLACE FUNCTION match_documents(
    query_embedding VECTOR(1536),
    match_threshold FLOAT,
    match_count INT,
    filter_user_id UUID DEFAULT NULL
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    metadata JSONB,
    similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        documents.id,
        documents.content,
        documents.metadata,
        1 - (documents.embedding <=> query_embedding) AS similarity
    FROM documents
    WHERE
        (filter_user_id IS NULL OR documents.user_id = filter_user_id)
        AND 1 - (documents.embedding <=> query_embedding) > match_threshold
    ORDER BY documents.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

### Prismaã‚¹ã‚­ãƒ¼ãƒæ‹¡å¼µ

```prisma
// prisma/schema.prisma
generator client {
  provider = "prisma-client-js"
  previewFeatures = ["postgresqlExtensions"]
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
  extensions = [pgvector(map: "vector")]
}

model Document {
  id        String   @id @default(uuid())
  userId    String
  content   String   @db.Text
  metadata  Json?
  embedding Unsupported("vector(1536)")?

  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@index([userId])
  @@map("documents")
}
```

## 4. Embeddingsç”Ÿæˆ

### OpenAI Embeddings API

```typescript
// lib/embeddings.ts
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function generateEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small', // 1536æ¬¡å…ƒ, ã‚³ã‚¹ãƒˆåŠ¹ç‡è‰¯ã„
    input: text,
    encoding_format: 'float',
  });

  return response.data[0].embedding;
}

// ãƒãƒƒãƒå‡¦ç†ç‰ˆï¼ˆæœ€å¤§2048å€‹ã¾ã§ï¼‰
export async function generateEmbeddings(
  texts: string[]
): Promise<number[][]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: texts,
  });

  return response.data.map((item) => item.embedding);
}
```

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²ï¼ˆChunkingï¼‰

```typescript
// lib/chunking.ts
interface ChunkOptions {
  chunkSize?: number; // æ–‡å­—æ•°
  chunkOverlap?: number; // ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
}

export function chunkDocument(
  text: string,
  options: ChunkOptions = {}
): string[] {
  const { chunkSize = 1000, chunkOverlap = 200 } = options;

  const chunks: string[] = [];
  let startIndex = 0;

  while (startIndex < text.length) {
    const endIndex = startIndex + chunkSize;
    const chunk = text.slice(startIndex, endIndex);
    chunks.push(chunk.trim());

    startIndex = endIndex - chunkOverlap;
  }

  return chunks;
}

// ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæ–‡ç« å˜ä½ï¼‰
export function semanticChunk(text: string): string[] {
  const sentences = text.match(/[^.!?]+[.!?]+/g) || [];
  const chunks: string[] = [];
  let currentChunk = '';

  for (const sentence of sentences) {
    if ((currentChunk + sentence).length > 1000 && currentChunk) {
      chunks.push(currentChunk.trim());
      currentChunk = sentence;
    } else {
      currentChunk += ' ' + sentence;
    }
  }

  if (currentChunk) {
    chunks.push(currentChunk.trim());
  }

  return chunks;
}
```

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```typescript
// lib/rag/ingest.ts
import { db } from '@/lib/db';
import { generateEmbedding } from '@/lib/embeddings';
import { semanticChunk } from '@/lib/chunking';

interface IngestDocumentParams {
  userId: string;
  content: string;
  metadata?: Record<string, any>;
}

export async function ingestDocument(params: IngestDocumentParams) {
  const { userId, content, metadata } = params;

  // 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²
  const chunks = semanticChunk(content);

  // 2. å„ãƒãƒ£ãƒ³ã‚¯ã‚’embeddingåŒ–ã—ã¦ä¿å­˜
  const documents = await Promise.all(
    chunks.map(async (chunk, index) => {
      const embedding = await generateEmbedding(chunk);

      return db.$executeRaw`
        INSERT INTO documents (user_id, content, metadata, embedding)
        VALUES (
          ${userId}::uuid,
          ${chunk},
          ${JSON.stringify({
            ...metadata,
            chunkIndex: index,
            totalChunks: chunks.length,
          })}::jsonb,
          ${embedding}::vector
        )
      `;
    })
  );

  return documents.length;
}

// ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ä¿å­˜æ™‚ã«è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
export async function indexNewsletter(newsletterId: string) {
  const newsletter = await db.newsletter.findUnique({
    where: { id: newsletterId },
    include: { analytics: true },
  });

  if (!newsletter) {
    throw new Error('Newsletter not found');
  }

  await ingestDocument({
    userId: newsletter.userId,
    content: `${newsletter.title}\n\n${newsletter.content}`,
    metadata: {
      type: 'newsletter',
      newsletterId: newsletter.id,
      status: newsletter.status,
      openRate: newsletter.analytics?.openRate,
      clickRate: newsletter.analytics?.clickRate,
    },
  });
}
```

## 5. æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…

### ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢é–¢æ•°

```typescript
// lib/rag/search.ts
import { db } from '@/lib/db';
import { generateEmbedding } from '@/lib/embeddings';

interface SearchParams {
  query: string;
  userId?: string;
  threshold?: number; // é¡ä¼¼åº¦ã—ãã„å€¤ï¼ˆ0.0-1.0ï¼‰
  limit?: number;
  filter?: Record<string, any>; // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿
}

export async function searchDocuments(params: SearchParams) {
  const {
    query,
    userId,
    threshold = 0.7,
    limit = 5,
    filter,
  } = params;

  // 1. ã‚¯ã‚¨ãƒªã‚’embeddingåŒ–
  const queryEmbedding = await generateEmbedding(query);

  // 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ
  const results = await db.$queryRaw<
    Array<{
      id: string;
      content: string;
      metadata: any;
      similarity: number;
    }>
  >`
    SELECT
      id,
      content,
      metadata,
      1 - (embedding <=> ${queryEmbedding}::vector) AS similarity
    FROM documents
    WHERE
      (${userId}::uuid IS NULL OR user_id = ${userId}::uuid)
      AND 1 - (embedding <=> ${queryEmbedding}::vector) > ${threshold}
      ${
        filter
          ? db.$queryRawUnsafe(
              `AND metadata @> '${JSON.stringify(filter)}'::jsonb`
            )
          : db.$queryRawUnsafe('')
      }
    ORDER BY embedding <=> ${queryEmbedding}::vector
    LIMIT ${limit}
  `;

  return results;
}

// éå»ã®æˆåŠŸã—ãŸãƒ¡ãƒ«ãƒã‚¬ã‚’æ¤œç´¢
export async function searchSuccessfulNewsletters(
  query: string,
  userId: string
) {
  return searchDocuments({
    query,
    userId,
    threshold: 0.75,
    limit: 3,
    filter: {
      type: 'newsletter',
      status: 'SENT',
    },
  });
}
```

### ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ« + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰

```typescript
// lib/rag/hybrid-search.ts
export async function hybridSearch(params: SearchParams) {
  const { query, userId, limit = 5 } = params;

  // 1. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
  const vectorResults = await searchDocuments(params);

  // 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆPostgreSQLå…¨æ–‡æ¤œç´¢ï¼‰
  const keywordResults = await db.$queryRaw<
    Array<{
      id: string;
      content: string;
      metadata: any;
      rank: number;
    }>
  >`
    SELECT
      id,
      content,
      metadata,
      ts_rank(to_tsvector('english', content), plainto_tsquery('english', ${query})) AS rank
    FROM documents
    WHERE
      (${userId}::uuid IS NULL OR user_id = ${userId}::uuid)
      AND to_tsvector('english', content) @@ plainto_tsquery('english', ${query})
    ORDER BY rank DESC
    LIMIT ${limit}
  `;

  // 3. çµæœã‚’ãƒãƒ¼ã‚¸ï¼ˆReciprocal Rank Fusionï¼‰
  const mergedResults = mergeSearchResults(vectorResults, keywordResults);

  return mergedResults.slice(0, limit);
}

function mergeSearchResults(vectorResults: any[], keywordResults: any[]) {
  const k = 60; // RRFå®šæ•°
  const scores = new Map<string, number>();

  vectorResults.forEach((result, index) => {
    const score = 1 / (k + index + 1);
    scores.set(result.id, (scores.get(result.id) || 0) + score);
  });

  keywordResults.forEach((result, index) => {
    const score = 1 / (k + index + 1);
    scores.set(result.id, (scores.get(result.id) || 0) + score);
  });

  return Array.from(scores.entries())
    .sort((a, b) => b[1] - a[1])
    .map(([id]) => vectorResults.find((r) => r.id === id) || keywordResults.find((r) => r.id === id))
    .filter(Boolean);
}
```

## 6. LangChainçµ±åˆ

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
npm install langchain @langchain/openai @langchain/community
```

### RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰

```typescript
// lib/rag/chain.ts
import { ChatOpenAI } from '@langchain/openai';
import { PromptTemplate } from '@langchain/core/prompts';
import { StringOutputParser } from '@langchain/core/output_parsers';
import { searchDocuments } from './search';

const llm = new ChatOpenAI({
  modelName: 'gpt-4',
  temperature: 0.7,
});

const promptTemplate = PromptTemplate.fromTemplate(`
ã‚ãªãŸã¯LetterOSã®ç·¨é›†é•·AIã§ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚è€ƒã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context}

è³ªå•: {question}

å›ç­”:
`);

export async function queryRAG(question: string, userId: string) {
  // 1. é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
  const relevantDocs = await searchDocuments({
    query: question,
    userId,
    limit: 3,
  });

  // 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
  const context = relevantDocs
    .map((doc) => `---\n${doc.content}\n(é¡ä¼¼åº¦: ${doc.similarity.toFixed(2)})`)
    .join('\n\n');

  // 3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
  const prompt = await promptTemplate.format({
    context,
    question,
  });

  // 4. LLMã§å›ç­”ç”Ÿæˆ
  const chain = llm.pipe(new StringOutputParser());
  const response = await chain.invoke(prompt);

  return {
    answer: response,
    sources: relevantDocs.map((doc) => ({
      id: doc.id,
      content: doc.content.slice(0, 200) + '...',
      similarity: doc.similarity,
    })),
  };
}
```

### ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹

```typescript
// app/api/ai/query/route.ts
import { NextRequest } from 'next/server';
import { StreamingTextResponse } from 'ai';
import { queryRAG } from '@/lib/rag/chain';

export const runtime = 'edge';

export async function POST(request: NextRequest) {
  const { question, userId } = await request.json();

  const stream = await queryRAGStream(question, userId);

  return new StreamingTextResponse(stream);
}

async function queryRAGStream(question: string, userId: string) {
  const relevantDocs = await searchDocuments({
    query: question,
    userId,
    limit: 3,
  });

  const context = relevantDocs.map((doc) => doc.content).join('\n\n');

  const stream = await llm.stream([
    {
      role: 'system',
      content: `ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚è€ƒã«ã—ã¦å›ç­”ã—ã¦ãã ã•ã„:\n\n${context}`,
    },
    {
      role: 'user',
      content: question,
    },
  ]);

  return stream;
}
```

## 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### Redisã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

```typescript
// lib/rag/cache.ts
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_URL!,
  token: process.env.UPSTASH_REDIS_TOKEN!,
});

export async function cachedSearch(params: SearchParams) {
  const cacheKey = `search:${JSON.stringify(params)}`;

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
  const cached = await redis.get(cacheKey);
  if (cached) {
    return JSON.parse(cached as string);
  }

  // æ¤œç´¢å®Ÿè¡Œ
  const results = await searchDocuments(params);

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ï¼ˆ5åˆ†é–“ï¼‰
  await redis.set(cacheKey, JSON.stringify(results), {
    ex: 300,
  });

  return results;
}
```

### ãƒãƒƒãƒEmbeddingç”Ÿæˆ

```typescript
// lib/rag/batch-ingest.ts
export async function batchIngestNewsletters(userId: string) {
  const newsletters = await db.newsletter.findMany({
    where: { userId, status: 'SENT' },
    include: { analytics: true },
  });

  // ãƒãƒƒãƒã§embeddingç”Ÿæˆï¼ˆåŠ¹ç‡çš„ï¼‰
  const contents = newsletters.map(
    (n) => `${n.title}\n\n${n.content}`
  );

  const embeddings = await generateEmbeddings(contents);

  // ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆ
  const values = newsletters.map((newsletter, index) => ({
    userId,
    content: contents[index],
    metadata: {
      type: 'newsletter',
      newsletterId: newsletter.id,
      openRate: newsletter.analytics?.openRate,
    },
    embedding: embeddings[index],
  }));

  await db.$executeRaw`
    INSERT INTO documents (user_id, content, metadata, embedding)
    SELECT * FROM jsonb_to_recordset(${JSON.stringify(values)}::jsonb)
    AS x(user_id uuid, content text, metadata jsonb, embedding vector)
  `;
}
```

## 8. å®Ÿè£…ä¾‹é›†

### ãƒ¡ãƒ«ãƒã‚¬ç”Ÿæˆã«RAGã‚’æ´»ç”¨

```typescript
// app/actions/ai-generate.ts
'use server';

import { auth } from '@/lib/auth';
import { searchSuccessfulNewsletters } from '@/lib/rag/search';
import { ChatOpenAI } from '@langchain/openai';

export async function generateNewsletterWithRAG(topic: string) {
  const session = await auth();

  // 1. éå»ã®æˆåŠŸãƒ¡ãƒ«ãƒã‚¬ã‚’æ¤œç´¢
  const successfulExamples = await searchSuccessfulNewsletters(
    topic,
    session!.user.id
  );

  // 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
  const examples = successfulExamples
    .map((doc) => `ã€é–‹å°ç‡${(doc.metadata.openRate * 100).toFixed(1)}%ã€‘\n${doc.content}`)
    .join('\n\n---\n\n');

  // 3. AIç”Ÿæˆ
  const llm = new ChatOpenAI({ modelName: 'gpt-4' });

  const response = await llm.invoke([
    {
      role: 'system',
      content: `ã‚ãªãŸã¯ãƒ¡ãƒ«ãƒã‚¬ç·¨é›†é•·ã§ã™ã€‚ä»¥ä¸‹ã®éå»ã®æˆåŠŸäº‹ä¾‹ã‚’å‚è€ƒã«ã€åŒã˜ãƒˆãƒ¼ãƒ³ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã§æ–°ã—ã„ãƒ¡ãƒ«ãƒã‚¬ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

éå»ã®æˆåŠŸäº‹ä¾‹:
${examples}`,
    },
    {
      role: 'user',
      content: `ã€Œ${topic}ã€ã«ã¤ã„ã¦ãƒ¡ãƒ«ãƒã‚¬ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚`,
    },
  ]);

  return response.content;
}
```

## ğŸŒ å‚ç…§ãƒªã‚½ãƒ¼ã‚¹

### å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

1. [LangChain RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/) - RAGå®Ÿè£…ã‚¬ã‚¤ãƒ‰
2. [pgvector Documentation](https://github.com/pgvector/pgvector) - ãƒ™ã‚¯ãƒˆãƒ«DB
3. [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings) - Embeddings API
4. [Supabase Vector](https://supabase.com/docs/guides/ai/vector-indexes) - Supabase Vector DB
5. [LangChain.js](https://js.langchain.com/docs/introduction/) - LangChain JavaScriptç‰ˆ

### å®Ÿè£…è¨˜äº‹ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

6. [Building RAG Applications](https://www.pinecone.io/learn/retrieval-augmented-generation/) - RAGè§£èª¬
7. [Vector Search Best Practices](https://www.elastic.co/blog/improving-information-retrieval-with-hybrid-search) - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
8. [Chunking Strategies](https://www.pinecone.io/learn/chunking-strategies/) - ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥
9. [RAG Evaluation](https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG) - RAGè©•ä¾¡æ‰‹æ³•
10. [Production RAG Systems](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1) - æœ¬ç•ªç’°å¢ƒRAG

---

**å®Ÿè£…æ™‚é–“ç›®å®‰**: åŸºæœ¬RAGå®Ÿè£… 2äººæ—¥ã€æœ€é©åŒ–ãƒ»çµ±åˆ 2-3äººæ—¥
